{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6d389f-70cf-4d30-9e5f-94ff39f6a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 1: Symbolic, unconditioned generation\n",
    "#Using GROOVE MIDI DATASET to generate drum patterns using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f726d916-def9-41cd-a3c3-a2c960e28060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The more imports the merrier?\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import hashlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from midiutil import MIDIFile\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d32df484-022a-49f1-9064-423c61593600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the Groove MIDI dataset\n",
    "class GrooveDatasetLoader:\n",
    "    def __init__(self, data_dir: str = \"./groove_data\"):\n",
    "        self.data_dir = data_dir\n",
    "        self.midi_dir = os.path.join(data_dir, \"groove\")\n",
    "        self.metadata_file = None\n",
    "        \n",
    "    def download_dataset(self):\n",
    "        self._find_metadata_file()\n",
    "        return self\n",
    "    \n",
    "    def _find_metadata_file(self):\n",
    "        possible_locations = [\n",
    "            os.path.join(self.data_dir, \"info.csv\"),\n",
    "            os.path.join(self.data_dir, \"groove\", \"info.csv\"),\n",
    "            os.path.join(self.data_dir, \"groove-v1.0.0\", \"info.csv\"),\n",
    "        ]\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.data_dir):\n",
    "            for file in files:\n",
    "                if file == \"info.csv\":\n",
    "                    possible_locations.append(os.path.join(root, file))\n",
    "        \n",
    "        for location in possible_locations:\n",
    "            if os.path.exists(location):\n",
    "                self.metadata_file = location\n",
    "                return\n",
    "    \n",
    "    def _safe_extract_zip(self, zip_path: str, extract_to: str):      \n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            for member in zip_ref.infolist():\n",
    "                filename = member.filename\n",
    "                filename = re.sub(r'[<>:\"|?*\\r\\n\\x00]', '_', filename)\n",
    "                \n",
    "                target_path = os.path.join(extract_to, filename)\n",
    "                \n",
    "                if member.is_dir():\n",
    "                    os.makedirs(target_path, exist_ok=True)\n",
    "                else:\n",
    "                    os.makedirs(os.path.dirname(target_path), exist_ok=True)\n",
    "                    \n",
    "                    try:\n",
    "                        with zip_ref.open(member) as source, open(target_path, \"wb\") as target:\n",
    "                            shutil.copyfileobj(source, target)\n",
    "                    except (OSError, IOError) as e:\n",
    "                        print(f\"Skipping file due to error: {filename} - {e}\")\n",
    "                        continue\n",
    "    \n",
    "    def load_metadata(self) -> pd.DataFrame:\n",
    "        if self.metadata_file is None or not os.path.exists(self.metadata_file):\n",
    "            return self._create_basic_metadata()\n",
    "        \n",
    "        df = pd.read_csv(self.metadata_file)\n",
    "        return df\n",
    "    \n",
    "    def _create_basic_metadata(self) -> pd.DataFrame:\n",
    "        midi_files = []\n",
    "        \n",
    "        # Find all MIDI files\n",
    "        for root, dirs, files in os.walk(self.data_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.mid'):\n",
    "                    full_path = os.path.join(root, file)\n",
    "                    relative_path = os.path.relpath(full_path, self.data_dir)\n",
    "                    midi_files.append({\n",
    "                        'midi_filename': relative_path,\n",
    "                        'split': self._infer_split(file),\n",
    "                        'style': self._infer_style(file),\n",
    "                        'drummer': self._infer_drummer(relative_path),\n",
    "                        'beat_type': 'beat'  # Default\n",
    "                    })\n",
    "        df = pd.DataFrame(midi_files)\n",
    "        return df\n",
    "    \n",
    "    def _infer_split(self, filename: str) -> str:\n",
    "        hash_val = int(hashlib.md5(filename.encode()).hexdigest(), 16)\n",
    "        if hash_val % 10 < 8:\n",
    "            return 'train'\n",
    "        elif hash_val % 10 == 8:\n",
    "            return 'validation'\n",
    "        else:\n",
    "            return 'test'\n",
    "    \n",
    "    def _infer_style(self, filename: str) -> str:\n",
    "        filename_lower = filename.lower()\n",
    "        styles = ['funk', 'rock', 'jazz', 'latin', 'afrobeat', 'blues', 'soul', 'hiphop']\n",
    "        for style in styles:\n",
    "            if style in filename_lower:\n",
    "                return style\n",
    "        return 'unknown'\n",
    "    \n",
    "    def _infer_drummer(self, relative_path: str) -> str:\n",
    "        parts = relative_path.split(os.sep)\n",
    "        for part in parts:\n",
    "            if part.startswith('drummer'):\n",
    "                return part\n",
    "        return 'unknown'\n",
    "    \n",
    "    def get_file_lists(self) -> Tuple[List[str], List[str], List[str]]:\n",
    "        df = self.load_metadata()\n",
    "        if df is None or len(df) == 0:\n",
    "            return [], [], []\n",
    "        \n",
    "        train_files = []\n",
    "        val_files = []\n",
    "        test_files = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            midi_path = os.path.join(self.data_dir, row['midi_filename'])\n",
    "            if os.path.exists(midi_path):\n",
    "                if row['split'] == 'train':\n",
    "                    train_files.append(midi_path)\n",
    "                elif row['split'] == 'validation':\n",
    "                    val_files.append(midi_path)\n",
    "                elif row['split'] == 'test':\n",
    "                    test_files.append(midi_path)\n",
    "                \n",
    "        # If no files found with metadata approach, scan directory directly\n",
    "        if len(train_files) + len(val_files) + len(test_files) == 0:\n",
    "            all_midi_files = []\n",
    "            for root, dirs, files in os.walk(self.data_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.mid'):\n",
    "                        all_midi_files.append(os.path.join(root, file))\n",
    "            \n",
    "            # Split files manually\n",
    "            random.shuffle(all_midi_files)\n",
    "            n_files = len(all_midi_files)\n",
    "            train_files = all_midi_files[:int(0.8 * n_files)]\n",
    "            val_files = all_midi_files[int(0.8 * n_files):int(0.9 * n_files)]\n",
    "            test_files = all_midi_files[int(0.9 * n_files):]\n",
    "            \n",
    "        return train_files, val_files, test_files\n",
    "    \n",
    "    def analyze_dataset(self):\n",
    "        df = self.load_metadata()\n",
    "        if df is None or len(df) == 0:\n",
    "            # Basic analysis without metadata\n",
    "            all_midi_files = []\n",
    "            for root, dirs, files in os.walk(self.data_dir):\n",
    "                for file in files:\n",
    "                    if file.endswith('.mid'):\n",
    "                        all_midi_files.append(os.path.join(root, file))\n",
    "            return\n",
    "        \n",
    "        print(\"\\n---GROOVE DATASET ANALYSIS---\")\n",
    "        print(f\"Total tracks: {len(df)}\")\n",
    "        \n",
    "        if 'duration' in df.columns:\n",
    "            print(f\"Total duration: {df['duration'].sum()/60:.1f} minutes\")\n",
    "            print(f\"Average duration: {df['duration'].mean():.1f} seconds\")\n",
    "        if 'beat_type' in df.columns:\n",
    "            print(f\"Beat types: {df['beat_type'].value_counts().to_dict()}\")\n",
    "        if 'style' in df.columns:\n",
    "            print(f\"Top styles:\")\n",
    "            for style, count in df['style'].value_counts().head(10).items():\n",
    "                print(f\"  {style}: {count}\")\n",
    "            top_styles = []\n",
    "            for style in df['style'].value_counts().head(4).keys():\n",
    "                top_styles.append(style)\n",
    "        if 'drummer' in df.columns:\n",
    "            print(f\"Number of drummers: {df['drummer'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7315f0a4-30f3-4873-bab9-b11697914668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRUM-SPECIFIC TOKENIZATION\n",
    "\n",
    "class DrumTokenizer:\n",
    "    \"\"\"\n",
    "    Specialized tokenizer for drum patterns using the Groove dataset drum mapping\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Groove dataset drum mapping (from the documentation you provided)\n",
    "        self.drum_mapping = {\n",
    "            36: \"Bass\",           # Kick\n",
    "            38: \"Snare\",          # Snare (Head)\n",
    "            40: \"Snare\",          # Snare (Rim) -> map to same as snare\n",
    "            37: \"Snare\",          # Snare X-Stick -> map to same as snare\n",
    "            42: \"HH_Closed\",      # HH Closed (Bow)\n",
    "            22: \"HH_Closed\",      # HH Closed (Edge) -> map to same\n",
    "            44: \"HH_Closed\",      # HH Pedal -> map to same\n",
    "            46: \"HH_Open\",        # HH Open (Bow)\n",
    "            26: \"HH_Open\",        # HH Open (Edge) -> map to same\n",
    "            43: \"Tom_High\",       # Tom 3 (Head) - High Floor Tom\n",
    "            45: \"Tom_Mid\",        # Tom 2 - Low Tom\n",
    "            48: \"Tom_Low\",        # Tom 1 - Hi-Mid Tom\n",
    "            49: \"Crash\",          # Crash 1 (Bow)\n",
    "            55: \"Crash\",          # Crash 1 (Edge) -> map to same\n",
    "            57: \"Crash\",          # Crash 2 (Bow) -> map to same\n",
    "            52: \"Crash\",          # Crash 2 (Edge) -> map to same\n",
    "            51: \"Ride\",           # Ride (Bow)\n",
    "            59: \"Ride\",           # Ride (Edge) -> map to same\n",
    "            53: \"Ride\",           # Ride (Bell) -> map to same\n",
    "        }\n",
    "        \n",
    "        # Create vocabulary\n",
    "        self.vocab = {\n",
    "            'PAD': 0,\n",
    "            'SOS': 1,\n",
    "            'EOS': 2,\n",
    "            'REST': 3,  # No drum hit\n",
    "        }\n",
    "        \n",
    "        # Add drum types\n",
    "        unique_drums = set(self.drum_mapping.values())\n",
    "        for drum in sorted(unique_drums):\n",
    "            self.vocab[drum] = len(self.vocab)\n",
    "        \n",
    "        # Add timing tokens (16th note resolution)\n",
    "        for i in range(16):  # 16 positions per bar in 4/4\n",
    "            self.vocab[f'POS_{i}'] = len(self.vocab)\n",
    "        \n",
    "        # Add velocity levels\n",
    "        for v in [32, 48, 64, 80, 96, 112, 127]:  # 7 velocity levels\n",
    "            self.vocab[f'VEL_{v}'] = len(self.vocab)\n",
    "        \n",
    "        self.vocab_size = len(self.vocab)\n",
    "        self.id_to_token = {v: k for k, v in self.vocab.items()}\n",
    "        \n",
    "        print(f\"Drum types: {sorted(unique_drums)}\")\n",
    "    \n",
    "    def midi_to_tokens(self, midi_path: str, bars_per_sequence: int = 2) -> List[int]:\n",
    "        try:\n",
    "            score = Score(midi_path)\n",
    "            tokens = [self.vocab['SOS']]\n",
    "            \n",
    "            # Get all drum notes\n",
    "            notes = []\n",
    "            for track in score.tracks:\n",
    "                for note in track.notes:\n",
    "                    if note.pitch in self.drum_mapping:\n",
    "                        notes.append({\n",
    "                            'time': note.time,\n",
    "                            'pitch': note.pitch,\n",
    "                            'velocity': note.velocity\n",
    "                        })\n",
    "            \n",
    "            if not notes:\n",
    "                return [self.vocab['SOS'], self.vocab['EOS']]\n",
    "            \n",
    "            notes.sort(key=lambda x: x['time'])\n",
    "            \n",
    "            # Convert to 16th note grid\n",
    "            ticks_per_beat = score.ticks_per_quarter\n",
    "            ticks_per_16th = ticks_per_beat // 4\n",
    "            \n",
    "            # Process in chunks of bars\n",
    "            max_time = notes[-1]['time']\n",
    "            bars_in_song = int(max_time / (ticks_per_beat * 4)) + 1\n",
    "            num_sequences = min(bars_in_song // bars_per_sequence, 8)\n",
    "            \n",
    "            for seq in range(num_sequences):\n",
    "                start_time = seq * bars_per_sequence * 4 * ticks_per_beat\n",
    "                end_time = (seq + 1) * bars_per_sequence * 4 * ticks_per_beat\n",
    "                \n",
    "                # Create 16th note grid for this sequence\n",
    "                grid_size = bars_per_sequence * 16\n",
    "                \n",
    "                for pos in range(grid_size):\n",
    "                    tokens.append(self.vocab[f'POS_{pos % 16}'])\n",
    "                    \n",
    "                    # Find notes at this position\n",
    "                    pos_time = start_time + pos * ticks_per_16th\n",
    "                    pos_notes = [n for n in notes \n",
    "                               if pos_time <= n['time'] < pos_time + ticks_per_16th]\n",
    "                    \n",
    "                    if not pos_notes:\n",
    "                        tokens.append(self.vocab['REST'])\n",
    "                    else:\n",
    "                        for note in pos_notes:\n",
    "                            drum_type = self.drum_mapping[note['pitch']]\n",
    "                            tokens.append(self.vocab[drum_type])\n",
    "                            \n",
    "                            vel = min([32, 48, 64, 80, 96, 112, 127], \n",
    "                                    key=lambda x: abs(x - note['velocity']))\n",
    "                            tokens.append(self.vocab[f'VEL_{vel}'])\n",
    "            \n",
    "            tokens.append(self.vocab['EOS'])\n",
    "            return tokens\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {midi_path}: {e}\")\n",
    "            return [self.vocab['SOS'], self.vocab['EOS']]\n",
    "    \n",
    "    def tokens_to_midi(self, tokens: List[int], output_path: str, bpm: int = 120):\n",
    "        midi = MIDIFile(1)\n",
    "        track = 0\n",
    "        midi.addTempo(track, 0, bpm)\n",
    "        midi.addTimeSignature(track, 0, 4, 2, 24)  # 4/4 time signature\n",
    "        \n",
    "        # Reverse drum mapping\n",
    "        unique_mapping = {}\n",
    "        for pitch, drum in self.drum_mapping.items():\n",
    "            if drum not in unique_mapping:\n",
    "                unique_mapping[drum] = pitch\n",
    "        \n",
    "        current_beat = 0.0\n",
    "        current_velocity = 64\n",
    "        note_duration = 0.25\n",
    "        current_bar = 0\n",
    "        beats_per_bar = 4\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            token_id = tokens[i]\n",
    "            token = self.id_to_token.get(token_id, 'UNK')\n",
    "            \n",
    "            if token.startswith('POS_'):\n",
    "                position = int(token.split('_')[1])\n",
    "                # Calculate absolute beat position\n",
    "                beat_in_bar = position / 4.0  # Convert 16th note position to beat\n",
    "                current_beat = current_bar * beats_per_bar + beat_in_bar\n",
    "                \n",
    "            elif token.startswith('VEL_'):\n",
    "                current_velocity = int(token.split('_')[1])\n",
    "                \n",
    "            elif token in unique_mapping:\n",
    "                # Add drum hit\n",
    "                pitch = unique_mapping[token]\n",
    "                midi.addNote(track, 9, pitch, current_beat, note_duration, current_velocity)\n",
    "                \n",
    "            elif token == 'REST':\n",
    "                pass  # No note to add\n",
    "                \n",
    "            elif token in ['SOS', 'EOS', 'PAD']:\n",
    "                if token == 'EOS':\n",
    "                    break\n",
    "                    \n",
    "            # Advance to next bar when we complete 16 positions\n",
    "            if token.startswith('POS_15'):  # Last position in bar\n",
    "                current_bar += 1\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        # Add final bar marker and ensure proper song structure\n",
    "        total_bars = current_bar + 1\n",
    "        print(f\"  Generated composition: {total_bars} bars at {bpm} BPM\")\n",
    "        \n",
    "        with open(output_path, \"wb\") as f:\n",
    "            midi.writeFile(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0c26e38-4f78-48a2-ba85-94d7bbf747c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRUM-SPECIFIC MODELS\n",
    "class DrumRNN(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embedding_dim: int = 128, \n",
    "                 hidden_dim: int = 256, num_layers: int = 2, dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, x, hidden=None):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        output = self.dropout(lstm_out)\n",
    "        output = self.fc(output)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10bf96dc-4ec4-409f-9029-6f3da1d879ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN TRAINING AND GENERATION FRAMEWORK\n",
    "class GrooveMusicGenerator:\n",
    "    \n",
    "    def __init__(self, model_type: str = 'rnn', top_styles: List[str] = None):\n",
    "        self.model_type = model_type\n",
    "        self.device = torch.device('cpu')\n",
    "        self.tokenizer = DrumTokenizer()\n",
    "        self.model = None\n",
    "        self.top_styles = top_styles\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if self.top_styles:\n",
    "            print(f\"Filtering training data to only include styles: {self.top_styles}\")\n",
    "\n",
    "    def _infer_style_from_filename(self, file_path: str) -> str:\n",
    "        \"\"\"Infer style from filename as fallback\"\"\"\n",
    "        filename_lower = os.path.basename(file_path).lower()\n",
    "        \n",
    "        # Common style keywords that might appear in filenames\n",
    "        style_keywords = {\n",
    "            'funk': 'funk',\n",
    "            'rock': 'rock', \n",
    "            'jazz': 'jazz',\n",
    "            'latin': 'latin',\n",
    "            'afrobeat': 'afrobeat',\n",
    "            'blues': 'blues',\n",
    "            'soul': 'soul',\n",
    "            'hiphop': 'hiphop',\n",
    "            'hip_hop': 'hiphop',\n",
    "            'pop': 'pop',\n",
    "            'reggae': 'reggae',\n",
    "            'country': 'country',\n",
    "            'gospel': 'gospel'\n",
    "        }\n",
    "        \n",
    "        for keyword, style in style_keywords.items():\n",
    "            if keyword in filename_lower:\n",
    "                return style\n",
    "        \n",
    "        return 'unknown'\n",
    "    \n",
    "    def prepare_data(self, train_files: List[str], val_files: List[str]):\n",
    "        \"\"\"Prepare drum data\"\"\"\n",
    "        print(\"Tokenizing drum MIDI files...\")\n",
    "        \n",
    "        self.train_sequences = []\n",
    "        self.val_sequences = []\n",
    "\n",
    "        loader = GrooveDatasetLoader()\n",
    "        df = loader.load_metadata()\n",
    "\n",
    "        if df is not None and len(df) > 0:\n",
    "            style_mapping = {}\n",
    "            for _, row in df.iterrows():\n",
    "                full_path = os.path.join(loader.data_dir, row['midi_filename'])\n",
    "                style_mapping[full_path] = row['style']\n",
    "        else:\n",
    "            style_mapping = {}\n",
    "\n",
    "        filtered_train_files = []\n",
    "        skipped_count = 0\n",
    "        \n",
    "        # Process training files\n",
    "        for file_path in train_files[:100]:\n",
    "            if self.top_styles:  # Only filter if top_styles is provided\n",
    "                if file_path in style_mapping:\n",
    "                    file_style = style_mapping[file_path]\n",
    "                else:\n",
    "                    # Fallback: infer style from filename\n",
    "                    file_style = self._infer_style_from_filename(file_path)\n",
    "                \n",
    "                # Check if this style is in our allowed list\n",
    "                style_match = any(allowed_style.lower() in file_style.lower() \n",
    "                                for allowed_style in self.top_styles)\n",
    "                \n",
    "                if not style_match:\n",
    "                    skipped_count += 1\n",
    "                    continue\n",
    "            \n",
    "            filtered_train_files.append(file_path)\n",
    "\n",
    "        if skipped_count > 0:\n",
    "            print(f\"Skipped {skipped_count} files due to style filtering\")\n",
    "        \n",
    "        # Process validation files\n",
    "        for i, file_path in enumerate(filtered_train_files):\n",
    "            tokens = self.tokenizer.midi_to_tokens(file_path)\n",
    "            if len(tokens) > 10:\n",
    "                self.train_sequences.append(tokens)\n",
    "        \n",
    "        # Process validation files (you can also filter these if desired)\n",
    "        for file_path in val_files[:20]:  # Smaller validation set\n",
    "            tokens = self.tokenizer.midi_to_tokens(file_path)\n",
    "            if len(tokens) > 10:\n",
    "                self.val_sequences.append(tokens)\n",
    "        \n",
    "        print(f\"Prepared {len(self.train_sequences)} training and {len(self.val_sequences)} validation sequences\")\n",
    "        \n",
    "        # Print style summary\n",
    "        if self.top_styles:\n",
    "            print(f\"Training data filtered to include only styles: {self.top_styles}\")\n",
    "    \n",
    "    def create_model(self):\n",
    "        if self.model_type == 'rnn':\n",
    "            self.model = DrumRNN(\n",
    "                vocab_size=self.tokenizer.vocab_size,\n",
    "                embedding_dim=128,\n",
    "                hidden_dim=256,\n",
    "                num_layers=2\n",
    "            ).to(self.device)\n",
    "            self.criterion = nn.CrossEntropyLoss(ignore_index=self.tokenizer.vocab['PAD'])\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "        print(f\"Created {self.model_type} model\")\n",
    "    \n",
    "    def train_model(self, epochs: int = 10):\n",
    "        if self.model_type == 'rnn':\n",
    "            print(f\"Training RNN for {epochs} epochs...\")\n",
    "            \n",
    "            # Create data loader\n",
    "            class DrumDataset(Dataset):\n",
    "                def __init__(self, sequences, seq_len=64):\n",
    "                    self.data = []\n",
    "                    for seq in sequences:\n",
    "                        for i in range(0, len(seq) - seq_len, seq_len // 2):\n",
    "                            self.data.append(seq[i:i + seq_len + 1])\n",
    "                \n",
    "                def __len__(self):\n",
    "                    return len(self.data)\n",
    "                \n",
    "                def __getitem__(self, idx):\n",
    "                    seq = self.data[idx]\n",
    "                    return torch.tensor(seq[:-1]), torch.tensor(seq[1:])\n",
    "            \n",
    "            train_dataset = DrumDataset(self.train_sequences)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "            \n",
    "            self.model.train()\n",
    "            for epoch in range(epochs):\n",
    "                total_loss = 0\n",
    "                for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    output, _ = self.model(data)\n",
    "                    loss = self.criterion(output.reshape(-1, self.tokenizer.vocab_size), \n",
    "                                        target.reshape(-1))\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    total_loss += loss.item()\n",
    "                \n",
    "                avg_loss = total_loss / len(train_loader)\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    def generate_drum_patterns(self, num_patterns: int = 1, pattern_length: int = 300) -> List[str]:\n",
    "        print(f\"Generating {num_patterns} extended drum pattern(s) of {pattern_length} beats...\")\n",
    "        \n",
    "        generated_files = []\n",
    "        \n",
    "        for i in range(num_patterns):\n",
    "            print(f\"Generating pattern {i+1}/{num_patterns} with {self.model_type} model...\")\n",
    "\n",
    "            self.model.eval()\n",
    "            tokens = [self.tokenizer.vocab['SOS']]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for step in range(pattern_length * 4):\n",
    "                    if step % 100 == 0:\n",
    "                        print(f\"    Generated {step}/{pattern_length * 4} tokens...\")\n",
    "                    \n",
    "                    input_seq = torch.tensor([tokens[-min(len(tokens), 100):]], dtype=torch.long).to(self.device)\n",
    "                    output, _ = self.model(input_seq)\n",
    "                    logits = output[0, -1, :]\n",
    "                    \n",
    "                    temperature = 0.8\n",
    "                    logits = logits / temperature\n",
    "                    \n",
    "                    top_k = 20\n",
    "                    top_k_logits, top_k_indices = torch.topk(logits, top_k)\n",
    "                    probs = F.softmax(top_k_logits, dim=-1)\n",
    "                    \n",
    "                    try:\n",
    "                        next_token_idx = torch.multinomial(probs, 1).item()\n",
    "                        next_token = top_k_indices[next_token_idx].item()\n",
    "                    except:\n",
    "                        next_token = torch.argmax(logits).item()\n",
    "                    \n",
    "                    if next_token == self.tokenizer.vocab['EOS']:\n",
    "                        print(f\"Reached EOS token at step {step}\")\n",
    "                        break\n",
    "                    \n",
    "                    tokens.append(next_token)\n",
    "            \n",
    "            # Convert to MIDI with extended duration\n",
    "            filename = f\"task1_{self.model_type}_300beats.mid\"\n",
    "            try:\n",
    "                # Set the tempo\n",
    "                self.tokenizer.tokens_to_midi(tokens, filename, bpm=120)  \n",
    "                generated_files.append(filename)\n",
    "                print(f\"Generated: {filename} ({len(tokens)} tokens)\")\n",
    "                \n",
    "                # Calculate approximate duration\n",
    "                duration_minutes = (pattern_length / 100) * (60 / 100)\n",
    "                print(f\"  Estimated duration: ~{duration_minutes:.1f} minutes\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error generating pattern {i+1}: {e}\")\n",
    "        \n",
    "        return generated_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6de9c4bc-ef2a-4e10-a254-6475b187242b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Task 1: Groove MIDI Dataset - Drum Pattern Generation ===\n",
      "\n",
      "\n",
      "---GROOVE DATASET ANALYSIS---\n",
      "Total tracks: 1150\n",
      "Total duration: 814.9 minutes\n",
      "Average duration: 42.5 seconds\n",
      "Beat types: {'fill': 647, 'beat': 503}\n",
      "Top styles:\n",
      "  rock: 281\n",
      "  hiphop: 91\n",
      "  funk: 77\n",
      "  punk: 58\n",
      "  neworleans/funk: 48\n",
      "  jazz: 46\n",
      "  rock/halftime: 37\n",
      "  latin/brazilian-baiao: 32\n",
      "  soul: 31\n",
      "  funk/purdieshuffle: 30\n",
      "Number of drummers: 10\n",
      "\n",
      "----------------------------------------\n",
      "Training: Drum RNN\n",
      "----------------------------------------\n",
      "Drum types: ['Bass', 'Crash', 'HH_Closed', 'HH_Open', 'Ride', 'Snare', 'Tom_High', 'Tom_Low', 'Tom_Mid']\n",
      "Using device: cpu\n",
      "Filtering training data to only include styles: ['rock', 'hiphop', 'funk', 'neworleans/funk']\n",
      "Tokenizing drum MIDI files...\n",
      "Skipped 34 files due to style filtering\n",
      "Prepared 42 training and 15 validation sequences\n",
      "Training data filtered to include only styles: ['rock', 'hiphop', 'funk', 'neworleans/funk']\n",
      "Created rnn model\n",
      "Training RNN for 20 epochs...\n",
      "Epoch 1/20, Loss: 3.2324\n",
      "Epoch 2/20, Loss: 2.5176\n",
      "Epoch 3/20, Loss: 1.7500\n",
      "Epoch 4/20, Loss: 1.4463\n",
      "Epoch 5/20, Loss: 1.3326\n",
      "Epoch 6/20, Loss: 1.2663\n",
      "Epoch 7/20, Loss: 1.2111\n",
      "Epoch 8/20, Loss: 1.1635\n",
      "Epoch 9/20, Loss: 1.1225\n",
      "Epoch 10/20, Loss: 1.0885\n",
      "Epoch 11/20, Loss: 1.0481\n",
      "Epoch 12/20, Loss: 1.0150\n",
      "Epoch 13/20, Loss: 0.9822\n",
      "Epoch 14/20, Loss: 0.9509\n",
      "Epoch 15/20, Loss: 0.9189\n",
      "Epoch 16/20, Loss: 0.8914\n",
      "Epoch 17/20, Loss: 0.8639\n",
      "Epoch 18/20, Loss: 0.8322\n",
      "Epoch 19/20, Loss: 0.8013\n",
      "Epoch 20/20, Loss: 0.7732\n",
      "Generating 1 extended drum pattern(s) of 300 beats...\n",
      "Generating pattern 1/1 with rnn model...\n",
      "    Generated 0/1200 tokens...\n",
      "    Generated 100/1200 tokens...\n",
      "    Generated 200/1200 tokens...\n",
      "    Generated 300/1200 tokens...\n",
      "    Generated 400/1200 tokens...\n",
      "    Generated 500/1200 tokens...\n",
      "    Generated 600/1200 tokens...\n",
      "    Generated 700/1200 tokens...\n",
      "    Generated 800/1200 tokens...\n",
      "    Generated 900/1200 tokens...\n",
      "    Generated 1000/1200 tokens...\n",
      "    Generated 1100/1200 tokens...\n",
      "  Generated composition: 24 bars at 120 BPM\n",
      "Generated: task1_rnn_300beats.mid (1201 tokens)\n",
      "  Estimated duration: ~1.8 minutes\n"
     ]
    }
   ],
   "source": [
    "# MAIN EXECUTION\n",
    "\n",
    "def main():\n",
    "    print(\"=== Task 1: Groove MIDI Dataset - Drum Pattern Generation ===\\n\")\n",
    "    \n",
    "    loader = GrooveDatasetLoader()\n",
    "    loader.download_dataset()\n",
    "    loader.analyze_dataset()\n",
    "    top_styles = ['rock', 'hiphop', 'funk', 'neworleans/funk'] \n",
    "    \n",
    "    train_files, val_files, test_files = loader.get_file_lists()\n",
    "    \n",
    "    if not train_files:\n",
    "        print(\"No training files found. Please check dataset download.\")\n",
    "        return\n",
    "    \n",
    "    models_to_test = [\n",
    "        {'type': 'rnn', 'name': 'Drum RNN'}\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_config in models_to_test:\n",
    "        print(f\"\\n{'-'*40}\")\n",
    "        print(f\"Training: {model_config['name']}\")\n",
    "        print(f\"{'-'*40}\")\n",
    "        \n",
    "        try:\n",
    "            # Create generator\n",
    "            generator = GrooveMusicGenerator(model_type='rnn', top_styles=top_styles)\n",
    "            generator.prepare_data(train_files, val_files)\n",
    "            \n",
    "            # Create and train model  \n",
    "            generator.create_model()\n",
    "            generator.train_model(epochs=20)\n",
    "\n",
    "            # Generate extended patterns (300 beats each)\n",
    "            generated_files = generator.generate_drum_patterns(num_patterns=1, pattern_length=300)\n",
    "            \n",
    "            results[model_config['name']] = {\n",
    "                'generated_files': generated_files,\n",
    "                'model_type': model_config['type']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {model_config['name']}: {e}\")\n",
    "            continue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
